{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4) Maximum Likelihood.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM7xAnusg53GfgdibiG2TE0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6ERS_7BIghiH"},"outputs":[],"source":["import numpy as np\n","\n","\n","def coin_mle(data):\n","    \"\"\"\n","    Returns the learned probability of getting a heads using MLE.\n","    \n","    Parameters\n","    ----------\n","    data: list, array-like\n","        The list of observations. 1 for heads and 0 for tails.\n","    \n","    Returns\n","    -------\n","    theta: The learned probability of getting a heads.\n","    \"\"\"\n","    data = np.array(data)\n","    n_heads = np.sum(data)\n","\n","    return n_heads / data.size"]},{"cell_type":"code","source":["coin_mle([1, 1, 1, 0, 0])"],"metadata":{"id":"yMLJKiP7gsga","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646876225960,"user_tz":360,"elapsed":46,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"f2338f0a-b768-4044-cf8a-764a482e8d73"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["coin_mle([1, 1, 1, 0, 0, 0])"],"metadata":{"id":"wDX2wA5WgsqI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646876225961,"user_tz":360,"elapsed":39,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"86c45779-f437-41f9-e9fb-6b41c2e8d1d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["### MLE for normal distributions\n","\n","The normal distribution is parametrized by its mean and standard deviation and the distribution is given as follows: $P(x|\\mu,σ) = \\frac{1}{\\sqrt{2\\pi σ^2}} e^{\\frac{(x-\\mu)^2}{2σ^2}} $\n","\n","The likelihood is the probability of the data being observed, given the parameters. So, given the observed data, we can state the likelihood function as follows: $L(\\mu, \\sigma^2) = P(X|\\mu,σ^2) = Pr(x_1, ..., x_N|\\mu, σ^2) = ∏^N_{n=1}P(X|\\mu,σ^2) = ∏^N_{n=1} \\frac{1}{\\sqrt{2\\pi σ^2}} e^{\\frac{(x-\\mu)^2}{2σ^2}}   $"],"metadata":{"id":"7Z510g9TmURZ"}},{"cell_type":"code","source":["import numpy as np\n","\n","def gaussian_mle(data):\n","    \"\"\"\n","    Returns the learned parameters of the Normal Distribution using MLE.\n","    Parameters\n","    ----------\n","    data: list, array-like\n","        The list of observed variables.\n","    Returns\n","    -------\n","    \\mu: The learned mean of the Normal Distribution.\n","    \\sigma: The learned standard deviation of the Normal Distribution.\n","    \"\"\"\n","    data = np.array(data)\n","    mu = np.mean(data)\n","    variance = np.sqrt(np.mean((data - mu)**2))\n","    return mu, variance"],"metadata":{"id":"1neRktiigs_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from numpy.random import normal"],"metadata":{"id":"ry9Mca1CgtHE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = normal(loc=1, scale=2, size=10)"],"metadata":{"id":"ZuaczFtRlN0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"51gb8qx5gtcy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646876225967,"user_tz":360,"elapsed":38,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"7c178058-fa70-4ce4-aea2-e537a5ca8bbe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.52667196,  0.02500209,  2.09007582, -1.06386571,  1.91294937,\n","        3.02462072,  0.64428612,  3.66153366,  0.27519472,  0.90412091])"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["mu, sigma = gaussian_mle(data)"],"metadata":{"id":"v07-FalnlQQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mu"],"metadata":{"id":"YBi72ur-gtpQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646876225969,"user_tz":360,"elapsed":34,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"f5bebc5f-9f6f-496f-e0c3-503daae7782f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0947245748685188"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["sigma"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftSQyRxMluG_","executionInfo":{"status":"ok","timestamp":1646876225970,"user_tz":360,"elapsed":30,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"0c0c9f63-a803-4371-d2cf-230f05248c1e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.4600281693618726"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["data = normal(loc=1, scale=2, size=1000)\n","data[:10]"],"metadata":{"id":"cQ9tTHWTlwgS","executionInfo":{"status":"ok","timestamp":1646876225971,"user_tz":360,"elapsed":26,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a3de881b-aaca-44a5-b82a-6ad82854024b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 4.14905268,  1.09361053,  2.66125811,  3.00395662, -2.85138656,\n","       -0.62216494,  2.90116423,  2.44018189, -1.83470295, -1.1054538 ])"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["mu, sigma = gaussian_mle(data)"],"metadata":{"id":"6ugqRaFplwqc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mu"],"metadata":{"id":"rRcgZn55luZD","executionInfo":{"status":"ok","timestamp":1646876226062,"user_tz":360,"elapsed":13,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8bc50984-7592-4d31-81d0-66110c01c943"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.95993558419226"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["sigma"],"metadata":{"id":"lh22hLQYlul5","executionInfo":{"status":"ok","timestamp":1646876226064,"user_tz":360,"elapsed":13,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"979cd19c-8615-40d7-ea18-54c1e17b750b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.056662081155069"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["### The Baum-Welch algorithm (expectation maximization)\n","\n","The expectation maximization  (EM) algorithm (known as Baum-Welch  when applied to HMMs) is an iterative method used  to find the maximum likelihood  or maximum a posteriori  (MAP) estimates of parameters  in statistical models, where the model depends on unobserved  latent variables. The EM iteration alternates between performing an expectation  (E) step, which creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E  step. These parameter estimates are then used to determine the distribution of the latent variables in the next E  step.\n","\n","The EM algorithm starts with initial value of parameters $(θ^{\n","old})$. In the $E$ step, we take these\n","parameters and find the posterior distribution of latent variables $P(Z|X,θ^{\n","old})$. We then use\n","this posterior distribution to evaluate the expectation of the logarithm of the complete data\n","likelihood function, as a function of the parameters $θ$, to give the function $Q(θ,θ^{\n","old})$, defined\n","by the following: $Q(θ,θ^{\n","old})$ =$ \\sum_z Pr(Z|X,θ^{old} lnPr(X,Z|\\theta)$"],"metadata":{"id":"6wxR-aF60JwL"}},{"cell_type":"code","source":["!pip install hmmlearn"],"metadata":{"id":"pPKZ3JG50mIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install yfinance"],"metadata":{"id":"p2Ikd_lUXONC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import scipy as sp \n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from datetime import datetime, timedelta\n","import yfinance as yf\n","from hmmlearn.hmm import GaussianHMM"],"metadata":{"id":"3gvNhcYCXbjG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["today = datetime.today()\n","days = timedelta(days=500)\n","start = today-days"],"metadata":{"id":"Me-3-C86lsFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('start:', start, '\\t', 'end:', today)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhyxmkNkYPKU","executionInfo":{"status":"ok","timestamp":1646876234343,"user_tz":360,"elapsed":25,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"b1786a02-3f78-467d-db5b-5ffd1850e0eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["start: 2020-10-26 01:37:14.461805 \t end: 2022-03-10 01:37:14.461805\n"]}]},{"cell_type":"code","source":["stk = 'EBAY'\n","stk = yf.download(stk, start, today)\n","cl = stk['Adj Close']\n","vl = stk['Volume'][1:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YeGpF1pYYPjg","executionInfo":{"status":"ok","timestamp":1646876234486,"user_tz":360,"elapsed":160,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"f42e9fd6-a579-4fc4-e94c-0e7d6874c309"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r[*********************100%***********************]  1 of 1 completed\n"]}]},{"cell_type":"code","source":["ret = cl.pct_change(1)\n","ret.dropna(inplace=True)"],"metadata":{"id":"nSjGibFUcl4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = np.column_stack([ret, vl])"],"metadata":{"id":"lZEpDueCYQBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make an HMM instance and execute fit\n","model = GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=1000).fit(X)"],"metadata":{"id":"0g5hsnR7acqg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict the optimal sequence of internal hidden state\n","hidden_states = model.predict(X)"],"metadata":{"id":"CYa3B7Lcacz_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Transition matrix\")\n","print(model.transmat_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfTwssmubDzF","executionInfo":{"status":"ok","timestamp":1646876234720,"user_tz":360,"elapsed":124,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"3209a3c4-8c50-45ce-8af1-871bd382bcaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transition matrix\n","[[7.91660071e-01 3.98961713e-09 2.11706958e-18 2.08339925e-01]\n"," [8.54451453e-08 5.26792194e-01 4.57478207e-07 4.73207263e-01]\n"," [3.27473842e-58 8.15344173e-01 2.11417378e-11 1.84655827e-01]\n"," [2.93291055e-01 9.46583124e-04 8.52818706e-02 6.20480491e-01]]\n"]}]},{"cell_type":"code","source":["print(\"Means and vars of each hidden state\")\n","for i in range(model.n_components):\n","    print(\"{0}th hidden state\".format(i))\n","    print(\"mean = \", model.means_[i])\n","    print(\"var = \", np.diag(model.covars_[i]))\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Isz9tCZabEKm","executionInfo":{"status":"ok","timestamp":1646876234934,"user_tz":360,"elapsed":218,"user":{"displayName":"Evan Taylor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12178341209388566991"}},"outputId":"d31ea134-7496-408c-98fa-7e156995b93b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Means and vars of each hidden state\n","0th hidden state\n","mean =  [-1.39608837e-05  5.36828428e+06]\n","var =  [2.59800714e-04 1.10703292e+12]\n","\n","1th hidden state\n","mean =  [7.62206256e-03 1.21132237e+07]\n","var =  [1.21230391e-03 4.64908420e+12]\n","\n","2th hidden state\n","mean =  [-2.14156781e-02  2.17175937e+07]\n","var =  [3.58897684e-03 2.21903812e+13]\n","\n","3th hidden state\n","mean =  [1.37302452e-03 8.74210263e+06]\n","var =  [5.94983006e-04 2.65711640e+12]\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"VATQ7Xt8bEV7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"cEHSR8JladKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"gttCyghdadWs"},"execution_count":null,"outputs":[]}]}